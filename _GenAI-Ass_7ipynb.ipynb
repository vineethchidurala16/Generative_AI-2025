{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdDIgZ45glL81y2uKFd9Qf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vineethchidurala16/Generative_AI-2025/blob/main/_Gen_AI_7ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adagrad\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_excel(\"/content/diabetes.xls\")  # Change to your dataset\n",
        "\n",
        "\n",
        "# Split into features (X) and target (y)\n",
        "X = data.iloc[:, :-1].values  # All columns except the last\n",
        "y = data.iloc[:, -1].values   # Last column (target)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Save the scaler for future use\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "\n",
        "# Define the ANN model\n",
        "model = Sequential([\n",
        "    Dense(12, activation=\"swish\", input_shape=(X_train.shape[1],)),\n",
        "    Dense(25, activation=\"swish\"),\n",
        "    Dense(15, activation=\"swish\"),\n",
        "    Dense(1, activation=\"sigmoid\")  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adagrad(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=300, batch_size=16, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "# Predict classes\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Confusion matrix and classification report\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, target_names=[\"Non-Diabetic\", \"Diabetic\"])\n",
        "\n",
        "# Print results\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(report)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Non-Diabetic\", \"Diabetic\"],\n",
        "            yticklabels=[\"Non-Diabetic\", \"Diabetic\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Save the trained model\n",
        "model.save(\"diabetes_ann_model.keras\")\n",
        "print(\"Model saved successfully!\")\n",
        "\n",
        "# Load the trained model and scaler\n",
        "def load_trained_model():\n",
        "    return load_model(\"diabetes_ann_model.keras\"), joblib.load(\"scaler.pkl\")\n",
        "\n",
        "# Predict function\n",
        "def predict_diabetes(input_data):\n",
        "    model, scaler = load_trained_model()\n",
        "    input_array = np.array(input_data).reshape(1, -1)\n",
        "    input_scaled = scaler.transform(input_array)\n",
        "    prediction = model.predict(input_scaled)\n",
        "    return \"Diabetic\" if prediction > 0.5 else \"Non-Diabetic\"\n",
        "\n",
        "# Example input\n",
        "sample_input = [6, 148, 72, 35, 0, 33.6, 0.627, 50]  # Replace with real data\n",
        "result = predict_diabetes(sample_input)\n",
        "print(f\"Prediction: {result}\")"
      ],
      "metadata": {
        "id": "CS10feBWTMB7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9d95d811-7db3-4001-a05c-6b13d423b8e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.4277 - loss: 0.7132 - val_accuracy: 0.4481 - val_loss: 0.7099\n",
            "Epoch 2/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4642 - loss: 0.7067 - val_accuracy: 0.4935 - val_loss: 0.7066\n",
            "Epoch 3/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4808 - loss: 0.7046 - val_accuracy: 0.5000 - val_loss: 0.7037\n",
            "Epoch 4/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5220 - loss: 0.6980 - val_accuracy: 0.5065 - val_loss: 0.7013\n",
            "Epoch 5/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5708 - loss: 0.6969 - val_accuracy: 0.5325 - val_loss: 0.6989\n",
            "Epoch 6/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5630 - loss: 0.6925 - val_accuracy: 0.5714 - val_loss: 0.6968\n",
            "Epoch 7/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5822 - loss: 0.6882 - val_accuracy: 0.5844 - val_loss: 0.6947\n",
            "Epoch 8/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6102 - loss: 0.6839 - val_accuracy: 0.5974 - val_loss: 0.6928\n",
            "Epoch 9/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5870 - loss: 0.6892 - val_accuracy: 0.5974 - val_loss: 0.6910\n",
            "Epoch 10/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6218 - loss: 0.6822 - val_accuracy: 0.5974 - val_loss: 0.6893\n",
            "Epoch 11/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5880 - loss: 0.6897 - val_accuracy: 0.5974 - val_loss: 0.6876\n",
            "Epoch 12/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6364 - loss: 0.6805 - val_accuracy: 0.6234 - val_loss: 0.6860\n",
            "Epoch 13/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6286 - loss: 0.6794 - val_accuracy: 0.6299 - val_loss: 0.6844\n",
            "Epoch 14/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6213 - loss: 0.6764 - val_accuracy: 0.6169 - val_loss: 0.6829\n",
            "Epoch 15/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6064 - loss: 0.6764 - val_accuracy: 0.6169 - val_loss: 0.6814\n",
            "Epoch 16/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6360 - loss: 0.6721 - val_accuracy: 0.6234 - val_loss: 0.6800\n",
            "Epoch 17/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6452 - loss: 0.6661 - val_accuracy: 0.6299 - val_loss: 0.6785\n",
            "Epoch 18/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6624 - loss: 0.6661 - val_accuracy: 0.6299 - val_loss: 0.6771\n",
            "Epoch 19/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6503 - loss: 0.6614 - val_accuracy: 0.6299 - val_loss: 0.6757\n",
            "Epoch 20/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6344 - loss: 0.6676 - val_accuracy: 0.6234 - val_loss: 0.6744\n",
            "Epoch 21/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6335 - loss: 0.6607 - val_accuracy: 0.6234 - val_loss: 0.6730\n",
            "Epoch 22/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6332 - loss: 0.6651 - val_accuracy: 0.6169 - val_loss: 0.6718\n",
            "Epoch 23/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6698 - loss: 0.6556 - val_accuracy: 0.6234 - val_loss: 0.6705\n",
            "Epoch 24/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6611 - loss: 0.6534 - val_accuracy: 0.6234 - val_loss: 0.6692\n",
            "Epoch 25/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6489 - loss: 0.6566 - val_accuracy: 0.6169 - val_loss: 0.6679\n",
            "Epoch 26/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6241 - loss: 0.6614 - val_accuracy: 0.6234 - val_loss: 0.6667\n",
            "Epoch 27/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6618 - loss: 0.6514 - val_accuracy: 0.6234 - val_loss: 0.6654\n",
            "Epoch 28/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6585 - loss: 0.6511 - val_accuracy: 0.6169 - val_loss: 0.6642\n",
            "Epoch 29/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6759 - loss: 0.6465 - val_accuracy: 0.6104 - val_loss: 0.6630\n",
            "Epoch 30/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6465 - loss: 0.6517 - val_accuracy: 0.6104 - val_loss: 0.6618\n",
            "Epoch 31/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6520 - loss: 0.6470 - val_accuracy: 0.6104 - val_loss: 0.6606\n",
            "Epoch 32/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6554 - loss: 0.6461 - val_accuracy: 0.6104 - val_loss: 0.6595\n",
            "Epoch 33/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6223 - loss: 0.6501 - val_accuracy: 0.6039 - val_loss: 0.6583\n",
            "Epoch 34/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6301 - loss: 0.6459 - val_accuracy: 0.6039 - val_loss: 0.6571\n",
            "Epoch 35/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6386 - loss: 0.6431 - val_accuracy: 0.6039 - val_loss: 0.6559\n",
            "Epoch 36/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6857 - loss: 0.6316 - val_accuracy: 0.6039 - val_loss: 0.6548\n",
            "Epoch 37/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6121 - loss: 0.6554 - val_accuracy: 0.6039 - val_loss: 0.6536\n",
            "Epoch 38/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6737 - loss: 0.6329 - val_accuracy: 0.6039 - val_loss: 0.6525\n",
            "Epoch 39/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6662 - loss: 0.6318 - val_accuracy: 0.6039 - val_loss: 0.6514\n",
            "Epoch 40/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6703 - loss: 0.6350 - val_accuracy: 0.6039 - val_loss: 0.6502\n",
            "Epoch 41/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6598 - loss: 0.6370 - val_accuracy: 0.6039 - val_loss: 0.6491\n",
            "Epoch 42/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6628 - loss: 0.6307 - val_accuracy: 0.6039 - val_loss: 0.6480\n",
            "Epoch 43/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6453 - loss: 0.6364 - val_accuracy: 0.6039 - val_loss: 0.6469\n",
            "Epoch 44/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6500 - loss: 0.6286 - val_accuracy: 0.6039 - val_loss: 0.6458\n",
            "Epoch 45/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6635 - loss: 0.6241 - val_accuracy: 0.6169 - val_loss: 0.6446\n",
            "Epoch 46/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6722 - loss: 0.6242 - val_accuracy: 0.6169 - val_loss: 0.6435\n",
            "Epoch 47/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6501 - loss: 0.6269 - val_accuracy: 0.6169 - val_loss: 0.6424\n",
            "Epoch 48/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6551 - loss: 0.6217 - val_accuracy: 0.6169 - val_loss: 0.6413\n",
            "Epoch 49/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7009 - loss: 0.6165 - val_accuracy: 0.6234 - val_loss: 0.6402\n",
            "Epoch 50/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6538 - loss: 0.6227 - val_accuracy: 0.6169 - val_loss: 0.6391\n",
            "Epoch 51/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6762 - loss: 0.6160 - val_accuracy: 0.6169 - val_loss: 0.6381\n",
            "Epoch 52/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6785 - loss: 0.6201 - val_accuracy: 0.6169 - val_loss: 0.6370\n",
            "Epoch 53/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6671 - loss: 0.6128 - val_accuracy: 0.6169 - val_loss: 0.6359\n",
            "Epoch 54/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6856 - loss: 0.6112 - val_accuracy: 0.6169 - val_loss: 0.6348\n",
            "Epoch 55/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6717 - loss: 0.6073 - val_accuracy: 0.6104 - val_loss: 0.6338\n",
            "Epoch 56/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6698 - loss: 0.6166 - val_accuracy: 0.6104 - val_loss: 0.6327\n",
            "Epoch 57/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6590 - loss: 0.6146 - val_accuracy: 0.6039 - val_loss: 0.6317\n",
            "Epoch 58/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6687 - loss: 0.6143 - val_accuracy: 0.6039 - val_loss: 0.6306\n",
            "Epoch 59/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6635 - loss: 0.6143 - val_accuracy: 0.6104 - val_loss: 0.6296\n",
            "Epoch 60/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6983 - loss: 0.6023 - val_accuracy: 0.6169 - val_loss: 0.6285\n",
            "Epoch 61/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6645 - loss: 0.6039 - val_accuracy: 0.6169 - val_loss: 0.6275\n",
            "Epoch 62/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6466 - loss: 0.6141 - val_accuracy: 0.6104 - val_loss: 0.6265\n",
            "Epoch 63/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6424 - loss: 0.6135 - val_accuracy: 0.6104 - val_loss: 0.6254\n",
            "Epoch 64/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6816 - loss: 0.6027 - val_accuracy: 0.6104 - val_loss: 0.6244\n",
            "Epoch 65/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6579 - loss: 0.5998 - val_accuracy: 0.6104 - val_loss: 0.6234\n",
            "Epoch 66/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6816 - loss: 0.5971 - val_accuracy: 0.6104 - val_loss: 0.6224\n",
            "Epoch 67/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6630 - loss: 0.5973 - val_accuracy: 0.6169 - val_loss: 0.6213\n",
            "Epoch 68/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6584 - loss: 0.6032 - val_accuracy: 0.6234 - val_loss: 0.6203\n",
            "Epoch 69/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6854 - loss: 0.5856 - val_accuracy: 0.6234 - val_loss: 0.6194\n",
            "Epoch 70/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6895 - loss: 0.5870 - val_accuracy: 0.6234 - val_loss: 0.6184\n",
            "Epoch 71/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6831 - loss: 0.5930 - val_accuracy: 0.6234 - val_loss: 0.6174\n",
            "Epoch 72/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6956 - loss: 0.5846 - val_accuracy: 0.6169 - val_loss: 0.6164\n",
            "Epoch 73/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6813 - loss: 0.5892 - val_accuracy: 0.6169 - val_loss: 0.6154\n",
            "Epoch 74/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6848 - loss: 0.5895 - val_accuracy: 0.6234 - val_loss: 0.6145\n",
            "Epoch 75/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6760 - loss: 0.5802 - val_accuracy: 0.6234 - val_loss: 0.6135\n",
            "Epoch 76/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6797 - loss: 0.5828 - val_accuracy: 0.6234 - val_loss: 0.6126\n",
            "Epoch 77/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6650 - loss: 0.5912 - val_accuracy: 0.6169 - val_loss: 0.6116\n",
            "Epoch 78/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7249 - loss: 0.5678 - val_accuracy: 0.6169 - val_loss: 0.6107\n",
            "Epoch 79/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6869 - loss: 0.5818 - val_accuracy: 0.6169 - val_loss: 0.6097\n",
            "Epoch 80/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6708 - loss: 0.5855 - val_accuracy: 0.6169 - val_loss: 0.6088\n",
            "Epoch 81/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6910 - loss: 0.5780 - val_accuracy: 0.6169 - val_loss: 0.6079\n",
            "Epoch 82/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6864 - loss: 0.5733 - val_accuracy: 0.6169 - val_loss: 0.6070\n",
            "Epoch 83/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6942 - loss: 0.5758 - val_accuracy: 0.6299 - val_loss: 0.6061\n",
            "Epoch 84/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6869 - loss: 0.5775 - val_accuracy: 0.6364 - val_loss: 0.6052\n",
            "Epoch 85/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7140 - loss: 0.5587 - val_accuracy: 0.6429 - val_loss: 0.6043\n",
            "Epoch 86/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6776 - loss: 0.5821 - val_accuracy: 0.6364 - val_loss: 0.6034\n",
            "Epoch 87/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7012 - loss: 0.5672 - val_accuracy: 0.6429 - val_loss: 0.6026\n",
            "Epoch 88/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6976 - loss: 0.5642 - val_accuracy: 0.6429 - val_loss: 0.6017\n",
            "Epoch 89/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7005 - loss: 0.5695 - val_accuracy: 0.6429 - val_loss: 0.6009\n",
            "Epoch 90/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6872 - loss: 0.5627 - val_accuracy: 0.6429 - val_loss: 0.6000\n",
            "Epoch 91/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7153 - loss: 0.5533 - val_accuracy: 0.6429 - val_loss: 0.5992\n",
            "Epoch 92/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7243 - loss: 0.5516 - val_accuracy: 0.6429 - val_loss: 0.5983\n",
            "Epoch 93/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7087 - loss: 0.5605 - val_accuracy: 0.6429 - val_loss: 0.5975\n",
            "Epoch 94/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7142 - loss: 0.5560 - val_accuracy: 0.6494 - val_loss: 0.5967\n",
            "Epoch 95/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7130 - loss: 0.5572 - val_accuracy: 0.6494 - val_loss: 0.5959\n",
            "Epoch 96/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7050 - loss: 0.5588 - val_accuracy: 0.6494 - val_loss: 0.5951\n",
            "Epoch 97/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7031 - loss: 0.5569 - val_accuracy: 0.6494 - val_loss: 0.5943\n",
            "Epoch 98/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6999 - loss: 0.5575 - val_accuracy: 0.6494 - val_loss: 0.5935\n",
            "Epoch 99/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6946 - loss: 0.5579 - val_accuracy: 0.6558 - val_loss: 0.5928\n",
            "Epoch 100/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7350 - loss: 0.5444 - val_accuracy: 0.6558 - val_loss: 0.5920\n",
            "Epoch 101/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7247 - loss: 0.5486 - val_accuracy: 0.6558 - val_loss: 0.5912\n",
            "Epoch 102/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7223 - loss: 0.5507 - val_accuracy: 0.6558 - val_loss: 0.5905\n",
            "Epoch 103/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6849 - loss: 0.5574 - val_accuracy: 0.6558 - val_loss: 0.5897\n",
            "Epoch 104/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6912 - loss: 0.5609 - val_accuracy: 0.6558 - val_loss: 0.5890\n",
            "Epoch 105/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6977 - loss: 0.5575 - val_accuracy: 0.6558 - val_loss: 0.5883\n",
            "Epoch 106/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7126 - loss: 0.5569 - val_accuracy: 0.6558 - val_loss: 0.5876\n",
            "Epoch 107/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7091 - loss: 0.5599 - val_accuracy: 0.6623 - val_loss: 0.5869\n",
            "Epoch 108/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7217 - loss: 0.5520 - val_accuracy: 0.6623 - val_loss: 0.5862\n",
            "Epoch 109/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6717 - loss: 0.5801 - val_accuracy: 0.6623 - val_loss: 0.5855\n",
            "Epoch 110/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6947 - loss: 0.5582 - val_accuracy: 0.6623 - val_loss: 0.5848\n",
            "Epoch 111/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6922 - loss: 0.5574 - val_accuracy: 0.6623 - val_loss: 0.5842\n",
            "Epoch 112/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7151 - loss: 0.5418 - val_accuracy: 0.6558 - val_loss: 0.5835\n",
            "Epoch 113/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7156 - loss: 0.5479 - val_accuracy: 0.6558 - val_loss: 0.5828\n",
            "Epoch 114/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7198 - loss: 0.5237 - val_accuracy: 0.6623 - val_loss: 0.5822\n",
            "Epoch 115/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7202 - loss: 0.5405 - val_accuracy: 0.6688 - val_loss: 0.5815\n",
            "Epoch 116/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7139 - loss: 0.5529 - val_accuracy: 0.6688 - val_loss: 0.5809\n",
            "Epoch 117/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7109 - loss: 0.5392 - val_accuracy: 0.6688 - val_loss: 0.5803\n",
            "Epoch 118/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7319 - loss: 0.5453 - val_accuracy: 0.6688 - val_loss: 0.5797\n",
            "Epoch 119/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6822 - loss: 0.5581 - val_accuracy: 0.6753 - val_loss: 0.5791\n",
            "Epoch 120/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7139 - loss: 0.5340 - val_accuracy: 0.6818 - val_loss: 0.5785\n",
            "Epoch 121/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7190 - loss: 0.5375 - val_accuracy: 0.6818 - val_loss: 0.5779\n",
            "Epoch 122/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7086 - loss: 0.5404 - val_accuracy: 0.6818 - val_loss: 0.5773\n",
            "Epoch 123/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7288 - loss: 0.5193 - val_accuracy: 0.6818 - val_loss: 0.5768\n",
            "Epoch 124/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7311 - loss: 0.5294 - val_accuracy: 0.6883 - val_loss: 0.5762\n",
            "Epoch 125/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7382 - loss: 0.5270 - val_accuracy: 0.6883 - val_loss: 0.5757\n",
            "Epoch 126/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7452 - loss: 0.5250 - val_accuracy: 0.6883 - val_loss: 0.5751\n",
            "Epoch 127/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7257 - loss: 0.5313 - val_accuracy: 0.6883 - val_loss: 0.5746\n",
            "Epoch 128/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7366 - loss: 0.5195 - val_accuracy: 0.6948 - val_loss: 0.5740\n",
            "Epoch 129/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7228 - loss: 0.5336 - val_accuracy: 0.6948 - val_loss: 0.5735\n",
            "Epoch 130/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7553 - loss: 0.5129 - val_accuracy: 0.6948 - val_loss: 0.5730\n",
            "Epoch 131/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7239 - loss: 0.5250 - val_accuracy: 0.7013 - val_loss: 0.5725\n",
            "Epoch 132/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7248 - loss: 0.5482 - val_accuracy: 0.7013 - val_loss: 0.5720\n",
            "Epoch 133/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7355 - loss: 0.5226 - val_accuracy: 0.7013 - val_loss: 0.5715\n",
            "Epoch 134/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7017 - loss: 0.5450 - val_accuracy: 0.7013 - val_loss: 0.5710\n",
            "Epoch 135/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7345 - loss: 0.5252 - val_accuracy: 0.7013 - val_loss: 0.5705\n",
            "Epoch 136/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6962 - loss: 0.5476 - val_accuracy: 0.7013 - val_loss: 0.5701\n",
            "Epoch 137/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7377 - loss: 0.5349 - val_accuracy: 0.7013 - val_loss: 0.5696\n",
            "Epoch 138/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7058 - loss: 0.5314 - val_accuracy: 0.7013 - val_loss: 0.5691\n",
            "Epoch 139/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7089 - loss: 0.5309 - val_accuracy: 0.7013 - val_loss: 0.5687\n",
            "Epoch 140/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6924 - loss: 0.5299 - val_accuracy: 0.7013 - val_loss: 0.5683\n",
            "Epoch 141/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7094 - loss: 0.5313 - val_accuracy: 0.7013 - val_loss: 0.5678\n",
            "Epoch 142/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7368 - loss: 0.5349 - val_accuracy: 0.7078 - val_loss: 0.5674\n",
            "Epoch 143/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7122 - loss: 0.5400 - val_accuracy: 0.7078 - val_loss: 0.5670\n",
            "Epoch 144/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7199 - loss: 0.5191 - val_accuracy: 0.7078 - val_loss: 0.5665\n",
            "Epoch 145/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7530 - loss: 0.5118 - val_accuracy: 0.7013 - val_loss: 0.5661\n",
            "Epoch 146/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7526 - loss: 0.5134 - val_accuracy: 0.7013 - val_loss: 0.5657\n",
            "Epoch 147/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7291 - loss: 0.5226 - val_accuracy: 0.7013 - val_loss: 0.5653\n",
            "Epoch 148/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6927 - loss: 0.5421 - val_accuracy: 0.7013 - val_loss: 0.5649\n",
            "Epoch 149/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7535 - loss: 0.4993 - val_accuracy: 0.7013 - val_loss: 0.5646\n",
            "Epoch 150/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7296 - loss: 0.5279 - val_accuracy: 0.7013 - val_loss: 0.5642\n",
            "Epoch 151/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7436 - loss: 0.5132 - val_accuracy: 0.7013 - val_loss: 0.5638\n",
            "Epoch 152/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7059 - loss: 0.5192 - val_accuracy: 0.7013 - val_loss: 0.5634\n",
            "Epoch 153/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7342 - loss: 0.5318 - val_accuracy: 0.7078 - val_loss: 0.5631\n",
            "Epoch 154/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7560 - loss: 0.5063 - val_accuracy: 0.7143 - val_loss: 0.5627\n",
            "Epoch 155/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7143 - loss: 0.5254 - val_accuracy: 0.7143 - val_loss: 0.5624\n",
            "Epoch 156/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7239 - loss: 0.5401 - val_accuracy: 0.7143 - val_loss: 0.5620\n",
            "Epoch 157/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7134 - loss: 0.5329 - val_accuracy: 0.7143 - val_loss: 0.5617\n",
            "Epoch 158/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7410 - loss: 0.5005 - val_accuracy: 0.7208 - val_loss: 0.5614\n",
            "Epoch 159/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7417 - loss: 0.5008 - val_accuracy: 0.7208 - val_loss: 0.5611\n",
            "Epoch 160/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7162 - loss: 0.5228 - val_accuracy: 0.7208 - val_loss: 0.5607\n",
            "Epoch 161/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7320 - loss: 0.5060 - val_accuracy: 0.7208 - val_loss: 0.5604\n",
            "Epoch 162/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7581 - loss: 0.5003 - val_accuracy: 0.7208 - val_loss: 0.5601\n",
            "Epoch 163/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7658 - loss: 0.4936 - val_accuracy: 0.7208 - val_loss: 0.5598\n",
            "Epoch 164/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7343 - loss: 0.5134 - val_accuracy: 0.7208 - val_loss: 0.5595\n",
            "Epoch 165/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7380 - loss: 0.5104 - val_accuracy: 0.7208 - val_loss: 0.5592\n",
            "Epoch 166/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7324 - loss: 0.5169 - val_accuracy: 0.7208 - val_loss: 0.5589\n",
            "Epoch 167/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7441 - loss: 0.5164 - val_accuracy: 0.7208 - val_loss: 0.5586\n",
            "Epoch 168/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7057 - loss: 0.5344 - val_accuracy: 0.7208 - val_loss: 0.5583\n",
            "Epoch 169/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7293 - loss: 0.5145 - val_accuracy: 0.7208 - val_loss: 0.5580\n",
            "Epoch 170/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7417 - loss: 0.5126 - val_accuracy: 0.7273 - val_loss: 0.5578\n",
            "Epoch 171/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7379 - loss: 0.5066 - val_accuracy: 0.7273 - val_loss: 0.5575\n",
            "Epoch 172/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7386 - loss: 0.5007 - val_accuracy: 0.7208 - val_loss: 0.5573\n",
            "Epoch 173/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7509 - loss: 0.4870 - val_accuracy: 0.7208 - val_loss: 0.5570\n",
            "Epoch 174/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7160 - loss: 0.5102 - val_accuracy: 0.7208 - val_loss: 0.5567\n",
            "Epoch 175/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7338 - loss: 0.5036 - val_accuracy: 0.7208 - val_loss: 0.5565\n",
            "Epoch 176/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7356 - loss: 0.5102 - val_accuracy: 0.7208 - val_loss: 0.5562\n",
            "Epoch 177/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7174 - loss: 0.5132 - val_accuracy: 0.7208 - val_loss: 0.5560\n",
            "Epoch 178/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7269 - loss: 0.5079 - val_accuracy: 0.7208 - val_loss: 0.5558\n",
            "Epoch 179/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7304 - loss: 0.5133 - val_accuracy: 0.7208 - val_loss: 0.5555\n",
            "Epoch 180/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7462 - loss: 0.4913 - val_accuracy: 0.7208 - val_loss: 0.5553\n",
            "Epoch 181/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7701 - loss: 0.4825 - val_accuracy: 0.7208 - val_loss: 0.5551\n",
            "Epoch 182/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7222 - loss: 0.5080 - val_accuracy: 0.7208 - val_loss: 0.5549\n",
            "Epoch 183/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7320 - loss: 0.5034 - val_accuracy: 0.7208 - val_loss: 0.5547\n",
            "Epoch 184/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7451 - loss: 0.4938 - val_accuracy: 0.7208 - val_loss: 0.5544\n",
            "Epoch 185/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7464 - loss: 0.4907 - val_accuracy: 0.7208 - val_loss: 0.5542\n",
            "Epoch 186/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7360 - loss: 0.5030 - val_accuracy: 0.7143 - val_loss: 0.5540\n",
            "Epoch 187/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7323 - loss: 0.5006 - val_accuracy: 0.7078 - val_loss: 0.5538\n",
            "Epoch 188/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7577 - loss: 0.4843 - val_accuracy: 0.7143 - val_loss: 0.5536\n",
            "Epoch 189/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7336 - loss: 0.5082 - val_accuracy: 0.7078 - val_loss: 0.5534\n",
            "Epoch 190/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7489 - loss: 0.4918 - val_accuracy: 0.7078 - val_loss: 0.5532\n",
            "Epoch 191/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7626 - loss: 0.4648 - val_accuracy: 0.7078 - val_loss: 0.5531\n",
            "Epoch 192/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7396 - loss: 0.4962 - val_accuracy: 0.7013 - val_loss: 0.5529\n",
            "Epoch 193/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7186 - loss: 0.5048 - val_accuracy: 0.7013 - val_loss: 0.5527\n",
            "Epoch 194/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7203 - loss: 0.4870 - val_accuracy: 0.7013 - val_loss: 0.5525\n",
            "Epoch 195/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7362 - loss: 0.4941 - val_accuracy: 0.7013 - val_loss: 0.5524\n",
            "Epoch 196/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7375 - loss: 0.4883 - val_accuracy: 0.7013 - val_loss: 0.5522\n",
            "Epoch 197/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7811 - loss: 0.4722 - val_accuracy: 0.7013 - val_loss: 0.5520\n",
            "Epoch 198/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7303 - loss: 0.4908 - val_accuracy: 0.7013 - val_loss: 0.5519\n",
            "Epoch 199/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7546 - loss: 0.5092 - val_accuracy: 0.7013 - val_loss: 0.5517\n",
            "Epoch 200/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7828 - loss: 0.4571 - val_accuracy: 0.7013 - val_loss: 0.5515\n",
            "Epoch 201/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7484 - loss: 0.4921 - val_accuracy: 0.7013 - val_loss: 0.5514\n",
            "Epoch 202/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7255 - loss: 0.4929 - val_accuracy: 0.7013 - val_loss: 0.5512\n",
            "Epoch 203/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7311 - loss: 0.4797 - val_accuracy: 0.7013 - val_loss: 0.5511\n",
            "Epoch 204/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7555 - loss: 0.4868 - val_accuracy: 0.7013 - val_loss: 0.5509\n",
            "Epoch 205/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7428 - loss: 0.4855 - val_accuracy: 0.7013 - val_loss: 0.5508\n",
            "Epoch 206/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7461 - loss: 0.4965 - val_accuracy: 0.7013 - val_loss: 0.5506\n",
            "Epoch 207/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7616 - loss: 0.4887 - val_accuracy: 0.7013 - val_loss: 0.5505\n",
            "Epoch 208/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7455 - loss: 0.4813 - val_accuracy: 0.7013 - val_loss: 0.5503\n",
            "Epoch 209/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7207 - loss: 0.5145 - val_accuracy: 0.7013 - val_loss: 0.5502\n",
            "Epoch 210/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7451 - loss: 0.4868 - val_accuracy: 0.7013 - val_loss: 0.5500\n",
            "Epoch 211/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7331 - loss: 0.4979 - val_accuracy: 0.7013 - val_loss: 0.5499\n",
            "Epoch 212/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7173 - loss: 0.5245 - val_accuracy: 0.7013 - val_loss: 0.5498\n",
            "Epoch 213/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7622 - loss: 0.4954 - val_accuracy: 0.7013 - val_loss: 0.5497\n",
            "Epoch 214/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7279 - loss: 0.4880 - val_accuracy: 0.7013 - val_loss: 0.5495\n",
            "Epoch 215/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7082 - loss: 0.5196 - val_accuracy: 0.7013 - val_loss: 0.5494\n",
            "Epoch 216/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7370 - loss: 0.4893 - val_accuracy: 0.7013 - val_loss: 0.5493\n",
            "Epoch 217/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7456 - loss: 0.4787 - val_accuracy: 0.7013 - val_loss: 0.5491\n",
            "Epoch 218/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7340 - loss: 0.5095 - val_accuracy: 0.7013 - val_loss: 0.5490\n",
            "Epoch 219/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7559 - loss: 0.4954 - val_accuracy: 0.7013 - val_loss: 0.5489\n",
            "Epoch 220/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7304 - loss: 0.4993 - val_accuracy: 0.7013 - val_loss: 0.5488\n",
            "Epoch 221/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7630 - loss: 0.4705 - val_accuracy: 0.7013 - val_loss: 0.5487\n",
            "Epoch 222/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7615 - loss: 0.4963 - val_accuracy: 0.7013 - val_loss: 0.5486\n",
            "Epoch 223/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7743 - loss: 0.4656 - val_accuracy: 0.7013 - val_loss: 0.5484\n",
            "Epoch 224/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7457 - loss: 0.5031 - val_accuracy: 0.7013 - val_loss: 0.5483\n",
            "Epoch 225/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7509 - loss: 0.4926 - val_accuracy: 0.7013 - val_loss: 0.5482\n",
            "Epoch 226/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7755 - loss: 0.4578 - val_accuracy: 0.6948 - val_loss: 0.5481\n",
            "Epoch 227/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7376 - loss: 0.4960 - val_accuracy: 0.6948 - val_loss: 0.5480\n",
            "Epoch 228/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7486 - loss: 0.4926 - val_accuracy: 0.7013 - val_loss: 0.5479\n",
            "Epoch 229/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7613 - loss: 0.4916 - val_accuracy: 0.7013 - val_loss: 0.5478\n",
            "Epoch 230/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7557 - loss: 0.4829 - val_accuracy: 0.7013 - val_loss: 0.5477\n",
            "Epoch 231/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7811 - loss: 0.4670 - val_accuracy: 0.7013 - val_loss: 0.5476\n",
            "Epoch 232/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7247 - loss: 0.5097 - val_accuracy: 0.7013 - val_loss: 0.5475\n",
            "Epoch 233/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7464 - loss: 0.4909 - val_accuracy: 0.7013 - val_loss: 0.5474\n",
            "Epoch 234/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7551 - loss: 0.4831 - val_accuracy: 0.7013 - val_loss: 0.5473\n",
            "Epoch 235/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7520 - loss: 0.4986 - val_accuracy: 0.6948 - val_loss: 0.5472\n",
            "Epoch 236/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7380 - loss: 0.5131 - val_accuracy: 0.6948 - val_loss: 0.5472\n",
            "Epoch 237/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7296 - loss: 0.5067 - val_accuracy: 0.6948 - val_loss: 0.5471\n",
            "Epoch 238/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7613 - loss: 0.4808 - val_accuracy: 0.6948 - val_loss: 0.5470\n",
            "Epoch 239/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7712 - loss: 0.4790 - val_accuracy: 0.6948 - val_loss: 0.5469\n",
            "Epoch 240/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7557 - loss: 0.4751 - val_accuracy: 0.6948 - val_loss: 0.5468\n",
            "Epoch 241/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7477 - loss: 0.5017 - val_accuracy: 0.6948 - val_loss: 0.5468\n",
            "Epoch 242/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7407 - loss: 0.4998 - val_accuracy: 0.6948 - val_loss: 0.5467\n",
            "Epoch 243/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7622 - loss: 0.4872 - val_accuracy: 0.6948 - val_loss: 0.5466\n",
            "Epoch 244/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7494 - loss: 0.4881 - val_accuracy: 0.6948 - val_loss: 0.5465\n",
            "Epoch 245/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7335 - loss: 0.5110 - val_accuracy: 0.6948 - val_loss: 0.5464\n",
            "Epoch 246/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7457 - loss: 0.4831 - val_accuracy: 0.7013 - val_loss: 0.5464\n",
            "Epoch 247/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7497 - loss: 0.4849 - val_accuracy: 0.7013 - val_loss: 0.5463\n",
            "Epoch 248/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7887 - loss: 0.4531 - val_accuracy: 0.7013 - val_loss: 0.5462\n",
            "Epoch 249/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7701 - loss: 0.4823 - val_accuracy: 0.7078 - val_loss: 0.5462\n",
            "Epoch 250/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7512 - loss: 0.4963 - val_accuracy: 0.7078 - val_loss: 0.5461\n",
            "Epoch 251/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7687 - loss: 0.4757 - val_accuracy: 0.7078 - val_loss: 0.5460\n",
            "Epoch 252/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7552 - loss: 0.4821 - val_accuracy: 0.7078 - val_loss: 0.5459\n",
            "Epoch 253/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7882 - loss: 0.4541 - val_accuracy: 0.7078 - val_loss: 0.5459\n",
            "Epoch 254/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7578 - loss: 0.4737 - val_accuracy: 0.7078 - val_loss: 0.5458\n",
            "Epoch 255/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7420 - loss: 0.4799 - val_accuracy: 0.7078 - val_loss: 0.5457\n",
            "Epoch 256/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7660 - loss: 0.4992 - val_accuracy: 0.7078 - val_loss: 0.5457\n",
            "Epoch 257/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7674 - loss: 0.4810 - val_accuracy: 0.7078 - val_loss: 0.5456\n",
            "Epoch 258/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7582 - loss: 0.4689 - val_accuracy: 0.7078 - val_loss: 0.5456\n",
            "Epoch 259/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7745 - loss: 0.4740 - val_accuracy: 0.7078 - val_loss: 0.5455\n",
            "Epoch 260/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7654 - loss: 0.4720 - val_accuracy: 0.7078 - val_loss: 0.5455\n",
            "Epoch 261/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7327 - loss: 0.4930 - val_accuracy: 0.7078 - val_loss: 0.5454\n",
            "Epoch 262/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7442 - loss: 0.5080 - val_accuracy: 0.7078 - val_loss: 0.5453\n",
            "Epoch 263/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7574 - loss: 0.4764 - val_accuracy: 0.7078 - val_loss: 0.5453\n",
            "Epoch 264/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7437 - loss: 0.4940 - val_accuracy: 0.7078 - val_loss: 0.5452\n",
            "Epoch 265/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7619 - loss: 0.4870 - val_accuracy: 0.7143 - val_loss: 0.5452\n",
            "Epoch 266/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7527 - loss: 0.4903 - val_accuracy: 0.7143 - val_loss: 0.5451\n",
            "Epoch 267/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7634 - loss: 0.4800 - val_accuracy: 0.7143 - val_loss: 0.5451\n",
            "Epoch 268/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7434 - loss: 0.4952 - val_accuracy: 0.7143 - val_loss: 0.5450\n",
            "Epoch 269/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7684 - loss: 0.4507 - val_accuracy: 0.7143 - val_loss: 0.5450\n",
            "Epoch 270/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7464 - loss: 0.5038 - val_accuracy: 0.7143 - val_loss: 0.5449\n",
            "Epoch 271/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7428 - loss: 0.4838 - val_accuracy: 0.7143 - val_loss: 0.5449\n",
            "Epoch 272/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7774 - loss: 0.4741 - val_accuracy: 0.7208 - val_loss: 0.5448\n",
            "Epoch 273/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7850 - loss: 0.4680 - val_accuracy: 0.7208 - val_loss: 0.5448\n",
            "Epoch 274/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7450 - loss: 0.4936 - val_accuracy: 0.7208 - val_loss: 0.5447\n",
            "Epoch 275/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7650 - loss: 0.4638 - val_accuracy: 0.7208 - val_loss: 0.5447\n",
            "Epoch 276/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7726 - loss: 0.4684 - val_accuracy: 0.7208 - val_loss: 0.5446\n",
            "Epoch 277/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7957 - loss: 0.4392 - val_accuracy: 0.7208 - val_loss: 0.5446\n",
            "Epoch 278/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7627 - loss: 0.4755 - val_accuracy: 0.7208 - val_loss: 0.5445\n",
            "Epoch 279/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7684 - loss: 0.5114 - val_accuracy: 0.7208 - val_loss: 0.5445\n",
            "Epoch 280/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7801 - loss: 0.4621 - val_accuracy: 0.7208 - val_loss: 0.5444\n",
            "Epoch 281/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7960 - loss: 0.4426 - val_accuracy: 0.7208 - val_loss: 0.5444\n",
            "Epoch 282/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7528 - loss: 0.4668 - val_accuracy: 0.7208 - val_loss: 0.5443\n",
            "Epoch 283/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7559 - loss: 0.4786 - val_accuracy: 0.7208 - val_loss: 0.5443\n",
            "Epoch 284/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7686 - loss: 0.4639 - val_accuracy: 0.7208 - val_loss: 0.5443\n",
            "Epoch 285/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7680 - loss: 0.4730 - val_accuracy: 0.7208 - val_loss: 0.5442\n",
            "Epoch 286/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7715 - loss: 0.4741 - val_accuracy: 0.7208 - val_loss: 0.5442\n",
            "Epoch 287/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7648 - loss: 0.4680 - val_accuracy: 0.7208 - val_loss: 0.5441\n",
            "Epoch 288/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7623 - loss: 0.4602 - val_accuracy: 0.7208 - val_loss: 0.5441\n",
            "Epoch 289/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7468 - loss: 0.4915 - val_accuracy: 0.7208 - val_loss: 0.5441\n",
            "Epoch 290/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7471 - loss: 0.4951 - val_accuracy: 0.7208 - val_loss: 0.5441\n",
            "Epoch 291/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7290 - loss: 0.4894 - val_accuracy: 0.7208 - val_loss: 0.5440\n",
            "Epoch 292/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7559 - loss: 0.4836 - val_accuracy: 0.7208 - val_loss: 0.5440\n",
            "Epoch 293/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7663 - loss: 0.4642 - val_accuracy: 0.7208 - val_loss: 0.5440\n",
            "Epoch 294/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7575 - loss: 0.4952 - val_accuracy: 0.7143 - val_loss: 0.5439\n",
            "Epoch 295/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7755 - loss: 0.4571 - val_accuracy: 0.7143 - val_loss: 0.5439\n",
            "Epoch 296/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7559 - loss: 0.4769 - val_accuracy: 0.7143 - val_loss: 0.5439\n",
            "Epoch 297/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7671 - loss: 0.4618 - val_accuracy: 0.7143 - val_loss: 0.5438\n",
            "Epoch 298/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7488 - loss: 0.4864 - val_accuracy: 0.7143 - val_loss: 0.5438\n",
            "Epoch 299/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7683 - loss: 0.4683 - val_accuracy: 0.7143 - val_loss: 0.5438\n",
            "Epoch 300/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7352 - loss: 0.4901 - val_accuracy: 0.7143 - val_loss: 0.5438\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6747 - loss: 0.5546 \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Test Accuracy: 0.7143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Non-Diabetic       0.78      0.77      0.78        99\n",
            "    Diabetic       0.60      0.62      0.61        55\n",
            "\n",
            "    accuracy                           0.71       154\n",
            "   macro avg       0.69      0.69      0.69       154\n",
            "weighted avg       0.72      0.71      0.72       154\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b081c7eb4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
            "Prediction: Diabetic\n"
          ]
        }
      ]
    }
  ]
}
